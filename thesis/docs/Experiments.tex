\chapter{Experimental Evaluation}
\label{ch:experiment}
In this chapter, we discuss the experiment that was conducted. In \cref{sec:GenerationOfInputInstances}, we describe how the AF instances were generated. Then, we describe the setup and environment in which the experiment was executed in \cref{sec:Setup}. Next, we split up the experiment into two programs, the faithful/spurious check in \cref{sec:FaithfulSpuriusCheck} and the concretizing arguments program in \cref{sec:ConcretizingArgumentsProgram}. For every program, we ran test-run instances (i.e., a test-run is a single program invocation, solving a specific task) according to the two approaches, i.e., \ BFS and DFS and investigated further the efficiency of the applied refinements to the corresponding semantics. Furthermore, we compared all the test-runs of the specific program and visualized the runtimes according to the semantics. For the faithful/spurious check program, we also compared the two extension mapping approaches.


\section{Generation of Input Instances}
\label{sec:GenerationOfInputInstances}
We generated the experiment instances with the previously mentioned scripts in \cref{sec:ImplementationsCreatingAFs}. To have a variety of AF inputs, we generated $25$ tests per generator approach, i.e., \ random-based, grid-based, and level-based. The $25$ tests per generator approach are grouped into five different sizes, which are $10$, $15$, $20$, $25$, and $30$. Since the AF generator uses a certain probability to create an attack, it is connected to a certain randomness. This randomness assures the versatility of AFs in the same argument amount group. The probability value was set to \texttt{0.5}, equivalent to a $50\%$ chance that an attack between two arguments might occur. Finally, the abstraction of the concrete AFs was realized with the clustering script described in \cref{sec:ImplementationsCreatingAFs}. 

The arguments to be concretized for the concretization algorithm were chosen in the AF generation script. For every instance, we chose a random amount (between $1$ and the total amount of arguments in the cluster) of arguments, which had to be concretized. The randomness of generation is essential to ensure that we did not pick AFs that contributed to a misleading runtime by picking favorable AFs.


\section{Experimental Setup}
\label{sec:Setup}
The experiment was conducted in a personal computer environment. The exact specification can be seen in \cref{table:ExperimentSpecs}. Generally, we used an AMD CPU with 6 cores and 12 Threads running the \textit{x86\_64} architecture. We had a total RAM of 16GB, which sometimes was not enough, and we had to add another 16GB of SWAP memory. Every test run was conducted on the same setup, running Linux as the primary OS. In total, $75$ different AFs were tested under various configurations. These included the usage of the BFS and DFS algorithm, the three covered semantics, e.g., conflict-free, admissible, and stable, and running with and without the refinements. A separate Python script managed the tests by running every test instance as a subprocess and setting the timeout to 300s.

\begin{table}[H]
    \centering
    \caption{Experiment Setup Specifications}
    \begin{tabular}{ |l|l| }
    \hline
        CPU-Model-Name & AMD Ryzen 5 3600\\
        CPU-Cores & 6\\
        CPU-Threads & 12\\
        CPU-Architecture & x86\_64\\
        CPU-Speed & 4.2 GHz\\
        RAM & Vengeance PRO 16 GB\\
        SWAP & 16 GB\\
        Operating System & Ubuntu 24.04 \\
    \hline
    \end{tabular}
\label{table:ExperimentSpecs}
\end{table}





\section{Checking Faithulness}
\label{sec:FaithfulSpuriusCheck}

This section presents the data collected from the program, which checks if an abstract AF is faithful or spurious. We compare BFS and DFS in \cref{subsec:faithfulComparisonBFSvsDFS}. For these tests, we split plots into three categories, i.e., the three AF generator procedures (random-based, grid-based, and level-based). All three categories are split again on the specific semantics, i.e., conflict-free, admissible, and stable. Then, we checked how much impact the refinements had on the corresponding semantics. Finally, we packed all the runtimes into one plot to show the influence of the different generator approaches and created a table to show the impact of the number of arguments from the AF. Next, we did the same for the concretizing arguments program in \cref{sec:ConcretizingArgumentsProgram}.

\subsection{Comparison of BFS and DFS}
\label{subsec:faithfulComparisonBFSvsDFS}

\newcommand{\plotWidth}{10cm}
\newcommand{\plotHeight}{8cm}
\newcommand{\plotHeightSmall}{5cm}


We implemented two approaches to check for faithfulness, i.e., BFS and DFS. Both were tested and showed different results according to the AFs generation procedure. Note that we had a total amount of $450$ test-runs, split up into 9 plots (i.e., each plot has $50$ test-runs, as we have 25 test instances per generator approach, each of which was executed twice: one with refinements and once without). The plots are structured in a way, s.t.\ every step on the y-axis represents a test-run instance (i.e.\ a single invocation of the program to solve a specific task) and the x-axis represents the runtime of the test-run instance in seconds. First of all, let us have a look at the runtime of the random-based generated test-runs depicted in \cref{fig:expfaithful/BFSvsDFS/random/CF}, \cref{fig:expfaithful/BFSvsDFS/random/AD} and \cref{fig:expfaithful/BFSvsDFS/random/ST}.
Note, that the numeration does not begin at $1$ because all the test-runs below 40 were trivial and could be solved in under a second. We assume that since the random-based approach has more attacks than the other approaches, the amount of semantics extensions is less. Thus, BFS and DFS are similar.




\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeightSmall,
            xlabel={Runtime [s]},
            ylabel={Test-run},
            xmin=-10, xmax=310,
            ymin=38, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt, densely dashed]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/random-based/CF/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/random-based/CF/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of random-based AFs over conflict-free semantics}
    \label{fig:expfaithful/BFSvsDFS/random/CF}
\end{figure}


\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeightSmall,
            ylabel={Test-run},
            xlabel={Runtime [s]},
            xmin=-10, xmax=310,
            ymin=38, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/random-based/AD/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/random-based/AD/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of random-based AFs over admissible semantics}
    \label{fig:expfaithful/BFSvsDFS/random/AD}
\end{figure}


\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeightSmall,
            ylabel={Test-run},
            xlabel={Runtime [s]},
            xmin=-10, xmax=310,
            ymin=38, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/random-based/ST/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/random-based/ST/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of random-based AFs over stable semantics}
    \label{fig:expfaithful/BFSvsDFS/random/ST}
\end{figure}




BFS and DFS differences increase when we change the AF generation approach to the grid-based procedure. In the plots depicted in \cref{fig:expfaithful/BFSvsDFS/grid/CF}, \cref{fig:expfaithful/BFSvsDFS/grid/AD} and \cref{fig:expfaithful/BFSvsDFS/grid/ST} we can observe, that DFS outperforms the BFS algorithm. Due to the grid-based AF generation procedure, we created AFs with many more semantic extensions than on the random-based approach. Since BFS needs to compute every extension to prove spuriousness and DFS checks after every computed extension for spuriousness, we obtain a better runtime for DFS if the AF is spurious. Since all the test-run instances were computed randomly, the chance of generating a spurious AF is more likely, the DFS algorithm is favored.




\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            ylabel={Test-run},
            xlabel={Runtime [s]},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/grid-based/CF/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/grid-based/CF/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of grid-based AFs over conflict-free semantics}
    \label{fig:expfaithful/BFSvsDFS/grid/CF}
\end{figure}


\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            ylabel={Test-run},
            xlabel={Runtime [s]},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/grid-based/AD/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/grid-based/AD/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of grid-based AFs over admissible semantics}
    \label{fig:expfaithful/BFSvsDFS/grid/AD}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            xlabel={Runtime [s]},
            ylabel={Test-run},
            xmin=-10, xmax=310,
            ymin=38, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/grid-based/ST/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/grid-based/ST/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of grid-based AFs over stable semantics}
    \label{fig:expfaithful/BFSvsDFS/grid/ST}
\end{figure}



The difference increases even further when the AF generator approach is changed to the level-based procedure. As we can see in \cref{fig:expfaithful/BFSvsDFS/level/CF}, \cref{fig:expfaithful/BFSvsDFS/level/AD} and \cref{fig:expfaithful/BFSvsDFS/level/ST}, DFS dominates BFS especially in the conflict-free and admissible semantics. This is due to the bigger size of the semantics extensions. Recall that the conflict-free sets are a subset of the admissible sets, and the admissible sets are a subset of the stable extensions.





\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            ylabel={Test-run},
            xlabel={Runtime [s]},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/level-based/CF/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/level-based/CF/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of level-based AFs over conflict-free semantics}
    \label{fig:expfaithful/BFSvsDFS/level/CF}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            ylabel={Test-run},
            xlabel={Runtime [s]},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/level-based/AD/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/level-based/AD/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of level-based AFs over admissible semantics}
    \label{fig:expfaithful/BFSvsDFS/level/AD}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            xlabel={Runtime [s]},
            ylabel={Test-run},
            xmin=-10, xmax=310,
            ymin=38, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/level-based/ST/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/level-based/ST/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of level-based AFs over stable semantics}
    \label{fig:expfaithful/BFSvsDFS/level/ST}
\end{figure}


Finally, we arranged the data into a single plot from all the generator approaches in \cref{fig:expfaithful/BFSvsDFS/OnePlot}. Here, we can see that DFS dominates in almost all of the test-runs on the BFS approach, and in the few cases where BFS is more efficient than DFS, it is by a minor factor. Especially with the AFs generated with the level-based procedure, DFS is way more efficient. This is because, on level-based AFs, we have far more extensions than on random-based ones, and computing all of them with the BFS algorithm leads to a lousy runtime. On the other hand, random-based AFs have far fewer extensions due to fewer attacks. Thus, BFS can be faster than DFS, since it does not have to deal with as many context switches.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            xlabel={Runtime BFS [s]},
            ylabel={Runtime DFS [s]},
            xmin=-10, xmax=310,
            ymin=-10, ymax=310,
            xtick={0, 100, 200, 300},
            ytick={0, 100, 200, 300},
            legend pos=north west,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
            set layers
        ]

        \addplot[only marks, color=c1, mark=+, mark options={line width=1pt}, mark size=4.5pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/all/random-based.dat};
        \addplot[only marks, color=c2, mark=triangle, mark options={line width=1pt}, mark size=4.5pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/all/level-based.dat};
        \addplot[only marks, color=c3, mark=o, mark options={line width=1pt}, mark size=4.5pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/BFSvsDFS/all/grid-based.dat};
        \legend{random-based, grid-based, level-based}
        \pgfonlayer{axis foreground}
            \addplot[color=black, thick, densely dashed] coordinates {(-10,-10) (310,310)};
        \endpgfonlayer
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of BFS and DFS grouped by generator approach}
    \label{fig:expfaithful/BFSvsDFS/OnePlot}
\end{figure}



\subsection{Impact of Refinements}
\label{subsec:ComparisonOfRefinementAndNoRefinementOnFaithfulProgram}

We implemented different refinements for each semantics. As data has shown, the refinements made for conflict-free semantics have a significant impact, as shown in \cref{fig:expfaithful/REFvsNOREF/grid-based} and \cref{fig:expfaithful/REFvsNOREF/level-based}. Note that we had a total amount of $450$ test-runs, but we only show the interesting conflict-free results with $50$ test-runs per AF generator. The plots are structured in a way, s.t.\ every step on the y-axis represents a test-run instance (i.e.\ a single invocation of the program to solve a specific task) and the x-axis represents the runtime of the test-run instance in seconds.
The refinement reduces the runtime significantly, especially for AFs with many conflict-free sets. We got some test-runs for the grid-based AFs, where we obtained a better result without the refinement. We hypothesize that the observed outliers may result from the DFS algorithm finding a spurious extension. Recall that the refinement for the conflict-free sets is to extract all the subsets from a computed conflict-free set. If all the subsets are faithful, we introduce many faithful/spurious checks, which leads to an increase in runtime that the DFS algorithm, without refinement, does not face. The same outlier can be seen the other way around in the grid-based plot at test-run 25. Here, the refinement extracted a subset of a computed conflict-free set, which was spurious. Without the refinement, no spurious set was found within the timeout. Besides conflict-free, the refinements made for admissible and stable only had a minor impact. We speculate that the SAT-Solver discarded the refinement for optimization reasons or the overhead of increasing the Boolean formula, which led to no significant improvement.


\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            ylabel={Test-run},
            xlabel={Runtime [s]},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/REFvsNOREF/grid-based/REF.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/REFvsNOREF/grid-based/NOREF.dat};
        \legend{Refined, Not-Refined}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of grid-based AFs over conflict-free semantics}
    \label{fig:expfaithful/REFvsNOREF/grid-based}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            xlabel={Runtime [s]},
            ylabel={Test-run},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/REFvsNOREF/level-based/REF.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/REFvsNOREF/level-based/NOREF.dat};
        \legend{Refined, Not-Refined}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of level-based AFs over conflict-free semantics}
    \label{fig:expfaithful/REFvsNOREF/level-based}
\end{figure}




\subsection{Comparison of all Test-runs}

In this section, we compare the data over all the test-run instances. In \cref{fig:expfaithful/REFvsNOREF/OnePlot}, we can see the performance of the refinements against no refinements. The scatter plot represents for every datapoint the runtime of the testcase with the refinements as the x-value and the runtime without the refinement as the y-value. There is no significant difference except for some outliers for admissible and stable. We hypothesize that due to the refinement, we pushed the SAT-Solver in a specific direction (like changing the seed), where he found some lucky spurious extensions. Nevertheless, most of the time, the refinements made for non-conflict-free semantics had no fundamental impact on the runtime. On the other hand, the refinement made for conflict-free semantics significantly improved the runtime, besides some outliers.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            xlabel={Runtime refinement [s]},
            ylabel={Runtime no-refinement [s]},
            xmin=-10, xmax=310,
            ymin=-10, ymax=310,
            xtick={0, 100, 200, 300},
            ytick={0, 100, 200, 300},
            legend style={at={(0.8,0.25)}},
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
            set layers
        ]

        \addplot[only marks, color=c1, mark=+, mark options={line width=1pt}, mark size=4.5pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/REFvsNOREF/all/random-based.dat};
        \addplot[only marks, color=c2, mark=triangle, mark options={line width=1pt}, mark size=4.5pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/REFvsNOREF/all/grid-based.dat};
        \addplot[only marks, color=c3, mark=o, mark options={line width=1pt}, mark size=4.5pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/REFvsNOREF/all/level-based.dat};
        \legend{conflict-free, admissible, stable}
        \pgfonlayer{axis foreground}
            \addplot[color=black, thick, densely dashed] coordinates {(-10,-10) (310,310)};
        \endpgfonlayer
        \end{axis}
    \end{tikzpicture}
    \caption{Performance comparison of Refinement and No-Refinement by Semantics}
    \label{fig:expfaithful/REFvsNOREF/OnePlot}
\end{figure}


Furthermore, we look at how many test-runs did not run into a timeout depending on the semantics and the mean runtime of the passed test cases. We ran a total amount of $900$ test-runs, split up into $3$ semantics leading to $300$ test-runs for each semantics and depicted the runtime of the solved instances. Note, that the y-axis represents the numeration of test-runs starting at $100$, since all the test-runs below were solved in seconds. The x-axis shows the runtime of the test-run. In \cref{fig:expfaithful/Semantics/OnePlot} we can observe that the most solvable semantics is the stable semantics. Following admissible semantics, the least solved test-runs have conflict-free semantics. The reason for this is the number of semantic extensions of the AFs. If an AF has many semantic extensions, the runtime of the faithful check increases.


\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeightSmall,
            xlabel={Runtime [s]},
            ylabel={Test-run},
            xmin=-10, xmax=310,
            ymin=90, ymax=310,
            xtick={0, 100, 200, 300},
            ytick={0, 100, 200, 300},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]

        \addplot[color=c1, line width=1.5pt, densely dashed]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/Semantics/CF.dat};
        \addplot[color=c2, line width=1.5pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/Semantics/AD.dat};
        \addplot[color=c3, line width=1.5pt, densely dotted]
            table [x=x, y=y, col sep=space] {docs/plot_data/faithful/Semantics/ST.dat};

        \legend{conflict-free, admissible, stable}
        \end{axis}
    \end{tikzpicture}
    \caption{Solved test-runs depending on semantics}
    \label{fig:expfaithful/Semantics/OnePlot}
\end{figure}


The data was arranged in a tabular format to enable a more comprehensive comparison from a higher-level viewpoint. We computed the mean value of the test-runs depending on the AF number of arguments and semantics. Furthermore, we excluded the runtime from the test runs that ran into a timeout and stated the exact amount. In \cref{table:ExperimentStatisticsFaithfulCheck}, we can observe that with the increase in the AF's size, the faithful/spurious check's runtime also increases. The same holds for the amount of timeouts.


\begin{table}[htb]
    \centering
    \caption{Test-runs Statistics spurious check mean runtime}
    \begin{tabular}{ |l|l|l|l| }
        \hline
            arguments amount & cf [s] (timeout)& adm [s] (timeout)& stb [s] (timeout)\\
        \hline
            10 &   0.29 \hfill(0/60)  &   0.20 \hfill (0/60)  &   0.09 \hfill (0/60) \\
            15 &   3.91 \hfill(0/60)  &   0.81 \hfill (0/60)  &   0.13 \hfill (0/60) \\
            20 &  28.69 \hfill(13/60) &   6.56 \hfill (0/60)  &   0.34 \hfill (0/60) \\
            25 &  13.85 \hfill(20/60) &  37.69 \hfill (0/60)  &   4.72 \hfill (0/60) \\
            30 &  35.41 \hfill(26/60) &  33.01 \hfill (32/60) &  10.97 \hfill (6/60) \\
        \hline
    \end{tabular}
\label{table:ExperimentStatisticsFaithfulCheck}
\end{table}


\subsection{Comparison of Faithful Check Approaches}
We tested the difference between the two faithful/spurious check approaches and compared them in \ref{fig:expfaithful/SATnoSATDiff}. Data shows that the SAT call approach is more efficient than the list comparison. This is because the list comparison needs to deconstruct the clusters. This is especially bad for AFs with clusters that have an enormous amount of argument.

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                width=\plotWidth/1.5,
                height=\plotHeight,
                xlabel={Runtime REF [s]},
                ylabel={Test-run},
                xmin=-10, xmax=310,
                ymin=90, ymax=220,
                xtick={0, 100, 200, 300},
                ytick={100, 125, 150, 175, 200},
                legend pos=south east,
                ymajorgrids=true,
                xmajorgrids=true,
                grid style=dashed,
            ]
    
            \addplot[color=c1, line width=1.5pt, densely dashed]
                table [x=x, y=y, col sep=space] {docs/plot_data/faithful/OldNewApproach/BFS_old.dat};
            \addplot[color=c2, line width=1.5pt]
                table [x=x, y=y, col sep=space] {docs/plot_data/faithful/OldNewApproach/BFS_new.dat};
    
            \legend{List Comparison, SAT Call}
            \end{axis}
        \end{tikzpicture}
        \subcaption{BFS algorithm}
        \label{fig:expfaithful/SATnoSATBFS}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                width=\plotWidth/1.5,
                height=\plotHeight,
                xlabel={Runtime REF [s]},
                xmin=-10, xmax=310,
                ymin=90, ymax=220,
                xtick={0, 100, 200, 300},
                ytick={100, 125, 150, 175, 200},
                legend pos=south east,
                ymajorgrids=true,
                xmajorgrids=true,
                grid style=dashed,
            ]
    
            \addplot[color=c1, line width=1.5pt, densely dashed]
                table [x=x, y=y, col sep=space] {docs/plot_data/faithful/OldNewApproach/DFS_old.dat};
            \addplot[color=c2, line width=1.5pt]
                table [x=x, y=y, col sep=space] {docs/plot_data/faithful/OldNewApproach/DFS_new.dat};
    
            \legend{List Comparison, SAT Call}
            \end{axis}
        \end{tikzpicture}
        \subcaption{DFS algorithm}
        \label{fig:expfaithful/SATnoSATDFS}
    \end{subfigure}
    \caption{Comparison of faithful/spurious algorithms}
    \label{fig:expfaithful/SATnoSATDiff}
\end{figure}





\section{Concretizing Arguments Program}
\label{sec:ConcretizingArgumentsProgram}

This section presents the data collected from the concretizing arguments program. We again split up the test-runs to be able to compare the impact of BFS and DFS in \cref{subsec:ComparisonOfBFSandDFSApproachForConretizingArguments}, and the comparison on the runtime of using the semantics-specific refinements is shown in \cref{subsec:ComparisonOfRefinementAndNoRefinementOnConcretizingProgram}. The comparison of BFS and DFS is again split into the three AF generator approaches. Each plot depicts the runtime of BFS and DFS with the generator procedure and the corresponding semantics. The same is done for the refinement comparison. Furthermore, we also show the correlation of execution runtime and the size of the AF with a table and how many instances of test-runs were solvable according to the semantics.


\subsection{Comparison of BFS and DFS}
\label{subsec:ComparisonOfBFSandDFSApproachForConretizingArguments}

Since the program for concretizing arguments uses the faithful/spurious check multiple times, we can compare the impact on the runtime of the BFS and DFS approaches. We start with the first AF generator procedure, i.e., the random-based approach. Here we created three plots: in \cref{fig:expconcretize/BFSvsDFS/random/CF} the conflict-free semantics is shown, in \cref{fig:expconcretize/BFSvsDFS/randomAD} we depicted the admissible semantics and in \cref{fig:expconcretize/BFSvsDFS/random/ST} the stable semantics. For these test-cases, the DFS approach dominates the BFS approach in every instance. We hypothesize that this is the repeated check of spurious AFs, which is more favorable for DFS. Furthermore, BFS not only stands no chance against DFS, but in most instances, it does not terminate before the timeout. This is especially critical for the admissible and stable semantics.

For the runtime on the DFS approach, most of the AFs created with the random-based procedure were trivial to solve, and some ran into a timeout once the complexity of the AFs increased.


\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            xlabel={Runtime [s]},
            ylabel={Test-run},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/random-based/CF/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/random-based/CF/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of random-based AFs over conflict-free semantics}
    \label{fig:expconcretize/BFSvsDFS/random/CF}
\end{figure}


\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            ylabel={Test-run},
            xlabel={Runtime [s]},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/random-based/AD/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/random-based/AD/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of random-based AFs over admissible semantics}
    \label{fig:expconcretize/BFSvsDFS/randomAD}
\end{figure}


\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            ylabel={Test-run},
            xlabel={Runtime [s]},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/random-based/ST/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/random-based/ST/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of random-based AFs over stable semantics}
    \label{fig:expconcretize/BFSvsDFS/random/ST}
\end{figure}

The second AFs generator procedure is the grid-based approach. Similar to the random-based approach, DFS dominates the BFS algorithm as shown in \cref{fig:expconcretize/BFSvsDFS/grid/CF}, \cref{fig:expconcretize/BFSvsDFS/grid/AD} and \cref{fig:expconcretize/BFSvsDFS/grid/ST}.


\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            xlabel={Runtime [s]},
            ylabel={Test-run},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/grid-based/CF/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/grid-based/CF/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of grid-based AFs over conflict-free semantics}
    \label{fig:expconcretize/BFSvsDFS/grid/CF}
\end{figure}


\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            ylabel={Test-run},
            xlabel={Runtime [s]},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/grid-based/AD/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/grid-based/AD/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of grid-based AFs over admissible semantics}
    \label{fig:expconcretize/BFSvsDFS/grid/AD}
\end{figure}

For stable semantics, the DFS approach managed to solve every test-run instance within the given time frame.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            ylabel={Test-run},
            xlabel={Runtime [s]},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/grid-based/ST/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/grid-based/ST/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of grid-based AFs over stable semantics}
    \label{fig:expconcretize/BFSvsDFS/grid/ST}
\end{figure}





Finally, the remaining AF generator approach is the level-based procedure. We produced three plots for every covered semantics, i.e., conflict-free in \cref{fig:expconcretize/BFSvsDFS/level/CF}, admissible in \cref{fig:expconcretize/BFSvsDFS/level/AD} and stable in \cref{fig:expconcretize/BFSvsDFS/level/ST}. Also, DFS dominates the BFS algorithm in all the test runs. In contrast to the grid-based approach, the level-based approach created AF instances, which were more challenging to solve for BFS and DFS. Also, for the stable semantics, two test-run instances ran into a timeout on the DFS algorithm. We speculate that due to the AF generation procedure, we generated AFs that remain spurious even after concretizing arguments.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            ylabel={Test-run},
            xlabel={Runtime [s]},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/level-based/CF/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/level-based/CF/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of level-based AFs over conflict-free semantics}
    \label{fig:expconcretize/BFSvsDFS/level/CF}
\end{figure}


\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            ylabel={Test-run},
            xlabel={Runtime [s]},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/level-based/AD/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/level-based/AD/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of level-based AFs over admissible semantics}
    \label{fig:expconcretize/BFSvsDFS/level/AD}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            xlabel={Runtime [s]},
            ylabel={Test-run},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/level-based/ST/BFS.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/level-based/ST/DFS.dat};
        \legend{BFS, DFS}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of level-based AFs over stable semantics}
    \label{fig:expconcretize/BFSvsDFS/level/ST}
\end{figure}


Finally, we grouped the data by the AF generator procedure and plugged it into a single plot. In \cref{fig:expconcretize/BFSvsDFS/OnePlot}, we can see how dominant the DFS algorithm is compared to the BFS approach. Every test-run instance is either on the diagonal, i.e., DFS is just as fast as BFS, or below, i.e., DFS is faster than BFS. 

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            xlabel={Runtime BFS [s]},
            ylabel={Runtime DFS [s]},
            xmin=-10, xmax=310,
            ymin=-10, ymax=310,
            xtick={0, 100, 200, 300},
            ytick={0, 100, 200, 300},
            legend pos=north west,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
            set layers
        ]

        \addplot[only marks, color=c1, mark=+, mark options={line width=1pt}, mark size=4.5pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/all/random-based.dat};
        \addplot[only marks, color=c2, mark=triangle, mark options={line width=1pt}, mark size=4.5pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/all/level-based.dat};
        \addplot[only marks, color=c3, mark=o, mark options={line width=1pt}, mark size=4.5pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/BFSvsDFS/all/grid-based.dat};
        \legend{random-based, grid-based, level-based}
        \pgfonlayer{axis foreground}
            \addplot[color=black, thick, densely dashed] coordinates {(-10,-10) (310,310)};
        \endpgfonlayer
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of BFS and DFS grouped by generator approach}
    \label{fig:expconcretize/BFSvsDFS/OnePlot}
\end{figure}


\subsection{Impact of Refinements}
\label{subsec:ComparisonOfRefinementAndNoRefinementOnConcretizingProgram}

The results of the impact of the semantic-specific refinements on the arguments concretizing program are shown in this section. As previously mentioned in the faithful/spurious check, the refinements made for admissible and stable did not significantly impact the runtime. We hypothesize that the SAT-Solver has discarded the refinements for optimization reasons for these two semantics. Nevertheless, the refinement made for conflict-free is not added to the Boolean formula. However, it is more of an iterative improvement added at runtime by adding all the subsets of a computed conflict-free set.

The runtime of the test-run instances for the conflict-free semantics grouped by refinement and no-refinement are shown in \cref{fig:expconcretize/REFvsNOREF/grid-based} for the AFs generated with the grid-based procedure and for the AFs generated with the level-based procedure in \cref{fig:expconcretize/REFvsNOREF/level-based}. In almost all the test-runs the refinement decreases the runtime of the computation especially for the level-based AFs. Nevertheless, some instances are more efficient without the refinements. We hypothesize that these instances are test-runs that use the DFS algorithm and have a better result since, without the refinement, the algorithm generates the semantic extensions in a different order. The order is crucial when using the DFS algorithm because if the spurious extension is found in an early stage, the algorithm can abort.

For BFS, the refinement for conflict-free semantics improves the runtime for every instance. This is because the subset extraction of a computed semantics extension is always faster than computing the extension with an SAT-Solver. Since BFS computes all the semantics extensions before checking for spuriousness, the refinement decreases the runtime.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            ylabel={Test-run},
            xlabel={Runtime [s]},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/REFvsNOREF/grid-based/REF.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/REFvsNOREF/grid-based/NOREF.dat};
        \legend{Refined, Not-Refined}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of grid-based AFs over conflict-free semantics}
    \label{fig:expconcretize/REFvsNOREF/grid-based}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            xlabel={Runtime [s]},
            ylabel={Test-run},
            xmin=-10, xmax=310,
            ymin=0, ymax=50,
            xtick={0, 100, 200, 300},
            ytick={0,10,20,30,40,50},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
        \addplot[color=c1, mark=square, mark options={solid, line width=0.5pt}, densely dashed, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/REFvsNOREF/level-based/REF.dat};
        \addplot[color=c2, mark=square, mark options={line width=0.5pt}, line width=1pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/REFvsNOREF/level-based/NOREF.dat};
        \legend{Refined, Not-Refined}
        \end{axis}
    \end{tikzpicture}
    \caption{Runtime of level-based AFs over conflict-free semantics}
    \label{fig:expconcretize/REFvsNOREF/level-based}
\end{figure}


\subsection{Comparison of all Test-runs}
In this section, we compare the efficiency of the refinements to the corresponding semantics in \cref{fig:expconcretize/REFvsNOREF/OnePlot}. As the plot shows, the refinements for admissible and stable had no significant impact. Nevertheless, for conflict-free semantics, refinement had a significant impact. Besides five outliers, the refinement decreased the runtime significantly.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeight,
            xlabel={Runtime REF [s]},
            ylabel={Runtime NO-REF [s]},
            xmin=-10, xmax=310,
            ymin=-10, ymax=310,
            xtick={0, 100, 200, 300},
            ytick={0, 100, 200, 300},
            legend style={at={(0.8,0.25)}},
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
            set layers
        ]

        \addplot[only marks, color=c1, mark=+, mark options={line width=1pt}, mark size=4.5pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/REFvsNOREF/all/random-based.dat};
        \addplot[only marks, color=c2, mark=triangle, mark options={line width=1pt}, mark size=4.5pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/REFvsNOREF/all/grid-based.dat};
        \addplot[only marks, color=c3, mark=o, mark options={line width=1pt}, mark size=4.5pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/REFvsNOREF/all/level-based.dat};
        \legend{conflict-free, admissible, stable}
        \pgfonlayer{axis foreground}
            \addplot[color=black, thick, densely dashed] coordinates {(-10,-10) (310,310)};
        \endpgfonlayer
        \end{axis}
    \end{tikzpicture}
    \caption{Performance comparison of Refinement and No-Refinement by Semantics}
    \label{fig:expconcretize/REFvsNOREF/OnePlot}
\end{figure}



In \cref{fig:expconcretize/Semantics/OnePlot} we visualize the runtimes of the test-run instances which did not timeout. We split the data into the three implemented semantics and observed that stable semantics is again the semantics, with the least amount of timeouts. But other than for the faithful/spurious check, for the concretizing arguments program, conflict-free and admissible semantics are very similar when compared to the runtime of the solved test-run instances.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\plotWidth,
            height=\plotHeightSmall,
            xlabel={Runtime [s]},
            ylabel={Test-run},
            xmin=-10, xmax=310,
            ymin=80, ymax=250,
            xtick={0, 100, 200, 300},
            ytick={0, 100, 200, 300},
            legend pos=south east,
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]

        \addplot[color=c1, line width=1.5pt, densely dashed]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/Semantics/CF.dat};
        \addplot[color=c2, line width=1.5pt]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/Semantics/AD.dat};
        \addplot[color=c3, line width=1.5pt, densely dotted]
            table [x=x, y=y, col sep=space] {docs/plot_data/concretize/Semantics/ST.dat};

        \legend{conflict-free, admissible, stable}
        \end{axis}
    \end{tikzpicture}
    \caption{Solved test-runs depending on semantics}
    \label{fig:expconcretize/Semantics/OnePlot}
\end{figure}

In \cref{table:ExperimentStatisticsConcretize}, we grouped the test-run instances by the argument amount of the AFs. We then computed the mean runtime for all the implemented semantics, i.e., conflict-free, admissible, and stable. Furthermore, we stated the test-run instances that did not terminate before the timeout of 300s. As the table shows, there is a direct correlation between the increase in arguments of an AF and the amount of timeouted test-runs. 


\begin{table}[H]
    \centering
    \caption{Test-runs Statistics concretize arguments mean runtime}
    \begin{tabular}{ |l|l|l|l| }
        \hline
            arguments amount & cf [s] (timeout)& adm [s] (timeout)& stb [s] (timeout)\\
        \hline
            10 & 18.13 \hfill (2/60)  &  33.07 \hfill (0/60)  &  33.20 \hfill (0/60) \\
            15 & 18.00 \hfill (0/60)  &  59.24 \hfill (6/60)  &  53.36 \hfill (6/60) \\
            20 & 64.17 \hfill (20/60) &  21.92 \hfill (16/60) &   1.61 \hfill (16/60) \\
            25 & 31.40 \hfill (27/60) &  40.55 \hfill (24/60) &  31.60 \hfill (22/60) \\
            30 & 31.89 \hfill (47/60) &  59.79 \hfill (43/60) &  19.33 \hfill (24/60) \\
        \hline
    \end{tabular}
\label{table:ExperimentStatisticsConcretize}
\end{table}


